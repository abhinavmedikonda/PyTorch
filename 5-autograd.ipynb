{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6f169a-5c75-4d6f-ac32-c76c7932ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e559422a-c1ca-413c-b3f4-537bbc39193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3282, 3.5274, 4.8635, 2.8723],\n",
       "        [3.7953, 2.5294, 1.4086, 3.9868],\n",
       "        [4.1560, 5.6738, 9.0083, 7.2372]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.rand(3,4) * 10\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65026f7a-b69f-458d-acc6-d72e580f456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1291, 1.5009, 7.4483, 7.6864],\n",
       "        [0.8085, 9.6288, 5.0776, 9.2781],\n",
       "        [6.9175, 4.5585, 4.5989, 4.8418]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.rand(3,4) * 10\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00bad40-72bb-440d-a7c4-b4718ae6cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3282, 3.5274, 4.8635, 2.8723],\n",
       "        [3.7953, 2.5294, 1.4086, 3.9868],\n",
       "        [4.1560, 5.6738, 9.0083, 7.2372]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd509e6-692f-4618-9ab8-c351cae211cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19.8608,  5.2943, 36.2247, 22.0776],\n",
       "        [ 3.0684, 24.3553,  7.1524, 36.9899],\n",
       "        [28.7493, 25.8637, 41.4284, 35.0412]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t1 * t2\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9582aa53-fee0-41a5-9ca4-6f3b2f45c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(t1.requires_grad)\n",
    "print(t2.requires_grad)\n",
    "print(t.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ec0762-e4c2-4205-a551-17dc12c3bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/d2pd89m53_n3_pyzbqfc850w0000gn/T/ipykernel_28119/1979799225.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(t.grad)\n"
     ]
    }
   ],
   "source": [
    "print(t1.grad)\n",
    "print(t2.grad)\n",
    "print(t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41a1e4a-d327-498a-ab8a-75d9649aaab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "<MulBackward0 object at 0x113b85690>\n"
     ]
    }
   ],
   "source": [
    "print(t1.grad_fn)\n",
    "print(t2.grad_fn)\n",
    "print(t.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4677f50-0814-4ae8-8fa8-c3bca73c9010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward0 at 0x113b85840>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (t1 * t2).mean()\n",
    "t.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15522f27-87b8-45de-9e25-b9cd847ac496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/d2pd89m53_n3_pyzbqfc850w0000gn/T/ipykernel_28119/1979799225.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(t.grad)\n"
     ]
    }
   ],
   "source": [
    "print(t1.grad)\n",
    "print(t2.grad)\n",
    "print(t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ea3ed3-f863-472a-82c6-a31f5a962f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36ceae37-7a07-4726-a693-f2de688abf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1774, 0.1251, 0.6207, 0.6405],\n",
      "        [0.0674, 0.8024, 0.4231, 0.7732],\n",
      "        [0.5765, 0.3799, 0.3832, 0.4035]])\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/d2pd89m53_n3_pyzbqfc850w0000gn/T/ipykernel_28119/1979799225.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(t.grad)\n"
     ]
    }
   ],
   "source": [
    "print(t1.grad)\n",
    "print(t2.grad)\n",
    "print(t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18efcec-8d61-43ea-97b8-e2d45e5f4635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result tensor: tensor([[27.9845, 10.5821, 14.5904,  8.6169],\n",
      "        [11.3858,  7.5883,  4.2258, 11.9604],\n",
      "        [12.4680, 17.0213, 27.0250, 21.7116]])\n",
      "requires_grad for t1: True\n",
      "requires_grad for t2: False\n",
      "requires_grad for t: False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    t = t1 * 3\n",
    "    print(f'result tensor: {t}')\n",
    "    print(f'requires_grad for t1: {t1.requires_grad}')\n",
    "    print(f'requires_grad for t2: {t2.requires_grad}')\n",
    "    print(f'requires_grad for t: {t.requires_grad}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9a003e-c789-4e9e-86e5-c447d48fe419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(t):\n",
    "    return t * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c06f3b0f-8898-4ee6-ac22-59bcc243a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_no_grad(t):\n",
    "    return t * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b175d3a5-baf9-4b4e-9146-69e736344b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.6563,  7.0547,  9.7270,  5.7446],\n",
       "        [ 7.5905,  5.0589,  2.8172,  7.9736],\n",
       "        [ 8.3120, 11.3476, 18.0166, 14.4744]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a74cd36-d607-487b-864d-ef7e1c4ff5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2582,  3.0018, 14.8966, 15.3728],\n",
       "        [ 1.6170, 19.2576, 10.1553, 18.5561],\n",
       "        [13.8350,  9.1169,  9.1978,  9.6836]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_no_grad(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8057cd5-d1d1-4e31-86ed-d63295029540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[46.6408, 17.6368, 24.3174, 14.3615],\n",
      "        [18.9763, 12.6471,  7.0431, 19.9340],\n",
      "        [20.7801, 28.3689, 45.0416, 36.1860]])\n",
      "tensor([[55.9689, 21.1642, 29.1809, 17.2338],\n",
      "        [22.7715, 15.1766,  8.4517, 23.9209],\n",
      "        [24.9361, 34.0427, 54.0499, 43.4231]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    t = t1 * 5\n",
    "    print(t)\n",
    "    with torch.enable_grad():\n",
    "        t = t1 * 6\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae1bdeb-b863-4ebd-a605-e524a513ca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/d2pd89m53_n3_pyzbqfc850w0000gn/T/ipykernel_28119/2463847826.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t_one = torch.tensor(t_buf, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[18.2450, 37.8430, 94.9440],\n",
       "        [28.9900, 77.3090, 61.5540]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_buf = torch.tensor([[1.8245, 3.7843, 9.4944],\n",
    "        [2.8990, 7.7309, 6.1554]]).multiply(10)\n",
    "t_one = torch.tensor(t_buf, requires_grad=True)\n",
    "# t_one = t_one.multiply(10)\n",
    "print(t_one.requires_grad)\n",
    "print(t_one.grad_fn)\n",
    "# t_one.requires_grad_()\n",
    "t_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5c8c48-269c-4546-b313-78de81fe559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.1511, 4.5034, 7.4889],\n",
       "        [8.2414, 9.7214, 0.0734]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_two = torch.rand(2,3) * 10\n",
    "print(t_two.requires_grad)\n",
    "print(t_two.grad_fn)\n",
    "t_two.requires_grad_()\n",
    "t_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0f2c3f6-19ab-4ed9-80b3-8f583c3406c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(t_one.grad)\n",
    "print(t_two.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a1aaf0b-d75e-4e31-ba17-32cbc65ccbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(59.0108, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (t_one + t_two).mean()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dd3a273-b05b-489b-ae81-8d7034968a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(t_one.requires_grad)\n",
    "print(t_two.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a727d94-b8ae-4e41-a2c7-1dd61ed0d9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1667, 0.1667, 0.1667],\n",
      "        [0.1667, 0.1667, 0.1667]])\n",
      "tensor([[0.1667, 0.1667, 0.1667],\n",
      "        [0.1667, 0.1667, 0.1667]])\n"
     ]
    }
   ],
   "source": [
    "result.backward()\n",
    "print(t_one.grad)\n",
    "print(t_two.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a61d4c-9bd7-43f7-a04f-819c57fd03c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.2450, 37.8430, 94.9440],\n",
       "        [28.9900, 77.3090, 61.5540]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached = torch.detach(t_one)\n",
    "detached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b0abfed-9feb-48dc-a843-77d8820cd199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e65e35a-c4b5-440f-aa1d-0eaebb0b09a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(106.2950, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (t_one + detached).mean()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9db1086-32b0-4a79-84e3-fda89691cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result.backward()\n",
    "print(t_one.grad)\n",
    "print(detached.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50204c70-4397-4bcd-a45b-00c36fad37a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
